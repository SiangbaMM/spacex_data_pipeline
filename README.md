# Overview

Welcome to this data pipeline journey where we will work with Python, pandas, Singer, Snowflake, dbt, SQL, Git, and GitHub. Don't worry if these tools are new. You and I will cover them step by step.

# Project Contents

Here is our agenda :

1. Data pipeline

- Set up your environment: Install Python and essential tools.
- Learn Git and GitHub: Create a repository for your project.
- Build the pipeline: Extract SpaceX data using Singer and Pandas.
- Load data into Snowflake: Store your raw data securely.
- Transform data with dbt: Clean and organise your data.
- Analyse data using SQL: Find insights in the launch data.

2. Data orchestration

- Install and run Airflow

2. API

- Using Flask
- Using FastAPI

3. Local Deployment

- Install and run the scheduled pipeline via Docker

4. Cloud deployment on Azure

- To be defined

# FAQ's

- If you have any questions or corrections, please open an issue and I'll get it merged ASAP
- For any other questions or concerns, just shoot me an email..
